# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# CORS Settings
FRONTEND_URL=http://localhost:3000

# LLM Provider Configuration
# Priority: FIREWORKS_API_KEY > GEMINI_API_KEY > OPENAI_API_KEY > Mock Provider
# Set LLM_PROVIDER to force a specific provider: "fireworks", "gemini", "openai"

# FireworksAI (recommended for best performance)
FIREWORKS_API_KEY=your_fireworks_api_key_here
FIREWORKS_MODEL=accounts/fireworks/models/qwen3-235b-a22b-instruct-2507

# Google Gemini (free tier available)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-lite

# OpenAI
# OPENAI_API_KEY=your_openai_key_here
# OPENAI_MODEL=gpt-3.5-turbo

# RAG Configuration
# Embedding model for semantic search (local model for cost efficiency)
EMBEDDING_MODEL=all-MiniLM-L6-v2
# Alternative models: all-mpnet-base-v2, all-distilroberta-v1, paraphrase-multilingual-MiniLM-L12-v2

# Other API Keys (add as needed)
# ANTHROPIC_API_KEY=your_anthropic_key_here
