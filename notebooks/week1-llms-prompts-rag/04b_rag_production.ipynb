{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6285cd3d",
   "metadata": {},
   "source": [
    "# RAG Production Patterns: Scaling, Monitoring, and Deployment\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Production RAG](#introduction)\n",
    "2. [Architecture Patterns](#architecture-patterns)\n",
    "3. [Scaling Strategies](#scaling-strategies)\n",
    "4. [Monitoring & Observability](#monitoring)\n",
    "5. [Deployment Patterns](#deployment-patterns)\n",
    "6. [Security & Compliance](#security)\n",
    "7. [Error Handling & Recovery](#error-handling)\n",
    "8. [Performance Tuning](#performance-tuning)\n",
    "9. [Cost Management](#cost-management)\n",
    "10. [Real-World Production Cases](#real-world-cases)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Production RAG {#introduction}\n",
    "\n",
    "Production RAG systems require robust patterns for scalability, reliability, and maintainability.\n",
    "\n",
    "### Key Production Requirements\n",
    "\n",
    "1. **Scalability**: Handle growing workloads\n",
    "2. **Reliability**: 99.9%+ uptime\n",
    "3. **Performance**: Sub-second response times\n",
    "4. **Security**: Data protection and access control\n",
    "5. **Monitoring**: Comprehensive observability\n",
    "6. **Cost Efficiency**: Optimized resource usage\n",
    "7. **Compliance**: Meet regulatory requirements\n",
    "8. **Maintainability**: Easy updates and debugging\n",
    "\n",
    "### Production Challenges\n",
    "\n",
    "1. **High Availability**: Ensure system availability\n",
    "2. **Data Consistency**: Maintain data integrity\n",
    "3. **Performance at Scale**: Handle peak loads\n",
    "4. **Security**: Protect sensitive data\n",
    "5. **Monitoring**: Track system health\n",
    "6. **Cost Control**: Manage operational costs\n",
    "7. **Compliance**: Meet regulatory requirements\n",
    "8. **Disaster Recovery**: Handle system failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q sentence-transformers qdrant-client openai python-dotenv tiktoken asyncio redis psutil prometheus-client fastapi uvicorn\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import json\n",
    "import hashlib\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import psutil\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import redis\n",
    "import pickle\n",
    "from prometheus_client import Counter, Histogram, Gauge, start_http_server\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All packages imported successfully!\")\n",
    "print(\"üîß Environment configured for production RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cee553",
   "metadata": {},
   "source": [
    "## Architecture Patterns {#architecture-patterns}\n",
    "\n",
    "Production RAG systems use various architecture patterns to meet scalability and reliability requirements.\n",
    "\n",
    "### 1. Microservices Architecture\n",
    "- **Service Separation**: Each component as independent service\n",
    "- **API Gateway**: Centralized request routing\n",
    "- **Service Discovery**: Dynamic service registration\n",
    "- **Load Balancing**: Distribute traffic across instances\n",
    "\n",
    "### 2. Event-Driven Architecture\n",
    "- **Event Streaming**: Asynchronous communication\n",
    "- **Event Sourcing**: Store events as source of truth\n",
    "- **CQRS**: Separate read and write models\n",
    "- **Saga Pattern**: Manage distributed transactions\n",
    "\n",
    "### 3. CQRS (Command Query Responsibility Segregation)\n",
    "- **Command Side**: Handle write operations\n",
    "- **Query Side**: Handle read operations\n",
    "- **Event Bus**: Synchronize between sides\n",
    "- **Read Models**: Optimized for queries\n",
    "\n",
    "### 4. Circuit Breaker Pattern\n",
    "- **Circuit States**: Closed, Open, Half-Open\n",
    "- **Failure Threshold**: Trigger circuit opening\n",
    "- **Recovery Testing**: Test service recovery\n",
    "- **Fallback Responses**: Graceful degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b08eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionRAGSystem:\n",
    "    \"\"\"Production-ready RAG system with enterprise patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_model: str = \"all-MiniLM-L6-v2\",\n",
    "                 redis_url: str = \"redis://localhost:6379\",\n",
    "                 enable_monitoring: bool = True):\n",
    "        \n",
    "        # Initialize components\n",
    "        self.embedder = SentenceTransformer(embedding_model)\n",
    "        self.redis_client = redis.from_url(redis_url) if redis_url else None\n",
    "        self.enable_monitoring = enable_monitoring\n",
    "        \n",
    "        # Initialize vector store\n",
    "        self.vector_client = QdrantClient(\":memory:\")\n",
    "        self.vector_client.create_collection(\n",
    "            collection_name=\"production_kb\",\n",
    "            vectors_config=VectorParams(\n",
    "                size=self.embedder.get_sentence_embedding_dimension(),\n",
    "                distance=Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Circuit breaker\n",
    "        self.circuit_breaker = CircuitBreaker(\n",
    "            failure_threshold=5,\n",
    "            recovery_timeout=60,\n",
    "            expected_exception=Exception\n",
    "        )\n",
    "        \n",
    "        # Monitoring\n",
    "        if enable_monitoring:\n",
    "            self.metrics = RAGMetrics()\n",
    "            self.metrics.start_server()\n",
    "        \n",
    "        # Caching\n",
    "        self.cache = ProductionCache(redis_client=self.redis_client)\n",
    "        \n",
    "        # Logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        print(f\"‚úÖ Production RAG system initialized\")\n",
    "        print(f\"üîß Embedding model: {embedding_model}\")\n",
    "        print(f\"üíæ Redis caching: {redis_url is not None}\")\n",
    "        print(f\"üìä Monitoring: {enable_monitoring}\")\n",
    "    \n",
    "    async def process_query(self, query: str, user_id: str = None) -> Dict[str, Any]:\n",
    "        \"\"\"Process query with production patterns\"\"\"\n",
    "        start_time = time.time()\n",
    "        request_id = self._generate_request_id()\n",
    "        \n",
    "        try:\n",
    "            # Log request\n",
    "            self.logger.info(f\"Processing query: {query[:100]}... (Request: {request_id})\")\n",
    "            \n",
    "            # Check circuit breaker\n",
    "            if not self.circuit_breaker.can_execute():\n",
    "                raise Exception(\"Circuit breaker is open\")\n",
    "            \n",
    "            # Check cache\n",
    "            cached_result = await self.cache.get(query)\n",
    "            if cached_result:\n",
    "                self.logger.info(f\"Cache hit for query: {query[:50]}...\")\n",
    "                return cached_result\n",
    "            \n",
    "            # Process query\n",
    "            result = await self._process_query_internal(query, request_id)\n",
    "            \n",
    "            # Cache result\n",
    "            await self.cache.set(query, result, ttl=3600)\n",
    "            \n",
    "            # Update metrics\n",
    "            if self.enable_monitoring:\n",
    "                self.metrics.record_query_success(time.time() - start_time)\n",
    "            \n",
    "            # Log success\n",
    "            self.logger.info(f\"Query processed successfully (Request: {request_id})\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Update metrics\n",
    "            if self.enable_monitoring:\n",
    "                self.metrics.record_query_error(str(e))\n",
    "            \n",
    "            # Log error\n",
    "            self.logger.error(f\"Query processing failed: {str(e)} (Request: {request_id})\")\n",
    "            \n",
    "            # Circuit breaker\n",
    "            self.circuit_breaker.record_failure()\n",
    "            \n",
    "            # Return fallback response\n",
    "            return await self._get_fallback_response(query, str(e))\n",
    "    \n",
    "    async def _process_query_internal(self, query: str, request_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Internal query processing logic\"\"\"\n",
    "        # Generate embedding\n",
    "        query_embedding = self.embedder.encode([query])[0]\n",
    "        \n",
    "        # Vector search\n",
    "        search_results = self.vector_client.search(\n",
    "            collection_name=\"production_kb\",\n",
    "            query_vector=query_embedding.tolist(),\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        # Generate response\n",
    "        context = \"\\n\".join([hit.payload[\"content\"] for hit in search_results])\n",
    "        response = f\"Based on the retrieved information: {context[:200]}...\"\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"results\": [hit.payload for hit in search_results],\n",
    "            \"request_id\": request_id,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "    \n",
    "    async def _get_fallback_response(self, query: str, error: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get fallback response when processing fails\"\"\"\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"response\": \"I apologize, but I'm experiencing technical difficulties. Please try again later.\",\n",
    "            \"results\": [],\n",
    "            \"error\": error,\n",
    "            \"fallback\": True,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "    \n",
    "    def _generate_request_id(self) -> str:\n",
    "        \"\"\"Generate unique request ID\"\"\"\n",
    "        return f\"req_{int(time.time() * 1000)}_{hashlib.md5(str(time.time()).encode()).hexdigest()[:8]}\"\n",
    "    \n",
    "    def get_system_health(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system health status\"\"\"\n",
    "        health = {\n",
    "            \"status\": \"healthy\",\n",
    "            \"timestamp\": time.time(),\n",
    "            \"components\": {}\n",
    "        }\n",
    "        \n",
    "        # Check vector store\n",
    "        try:\n",
    "            self.vector_client.get_collection(\"production_kb\")\n",
    "            health[\"components\"][\"vector_store\"] = \"healthy\"\n",
    "        except Exception as e:\n",
    "            health[\"components\"][\"vector_store\"] = f\"unhealthy: {str(e)}\"\n",
    "            health[\"status\"] = \"degraded\"\n",
    "        \n",
    "        # Check Redis\n",
    "        if self.redis_client:\n",
    "            try:\n",
    "                self.redis_client.ping()\n",
    "                health[\"components\"][\"redis\"] = \"healthy\"\n",
    "            except Exception as e:\n",
    "                health[\"components\"][\"redis\"] = f\"unhealthy: {str(e)}\"\n",
    "                health[\"status\"] = \"degraded\"\n",
    "        \n",
    "        # Check circuit breaker\n",
    "        health[\"components\"][\"circuit_breaker\"] = \"open\" if not self.circuit_breaker.can_execute() else \"closed\"\n",
    "        \n",
    "        # Check metrics\n",
    "        if self.enable_monitoring:\n",
    "            health[\"components\"][\"monitoring\"] = \"healthy\"\n",
    "            health[\"metrics\"] = self.metrics.get_summary()\n",
    "        \n",
    "        return health\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit breaker implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60, expected_exception: Exception = Exception):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.recovery_timeout = recovery_timeout\n",
    "        self.expected_exception = expected_exception\n",
    "        \n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "    \n",
    "    def can_execute(self) -> bool:\n",
    "        \"\"\"Check if circuit breaker allows execution\"\"\"\n",
    "        if self.state == \"CLOSED\":\n",
    "            return True\n",
    "        elif self.state == \"OPEN\":\n",
    "            if time.time() - self.last_failure_time > self.recovery_timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "                return True\n",
    "            return False\n",
    "        elif self.state == \"HALF_OPEN\":\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record successful execution\"\"\"\n",
    "        self.failure_count = 0\n",
    "        self.state = \"CLOSED\"\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record failed execution\"\"\"\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.failure_count >= self.failure_threshold:\n",
    "            self.state = \"OPEN\"\n",
    "\n",
    "class ProductionCache:\n",
    "    \"\"\"Production caching system with Redis\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_client: redis.Redis = None, default_ttl: int = 3600):\n",
    "        self.redis_client = redis_client\n",
    "        self.default_ttl = default_ttl\n",
    "        self.local_cache = {}  # Fallback local cache\n",
    "    \n",
    "    async def get(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"Get value from cache\"\"\"\n",
    "        if self.redis_client:\n",
    "            try:\n",
    "                value = self.redis_client.get(key)\n",
    "                if value:\n",
    "                    return pickle.loads(value)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Redis get failed: {e}\")\n",
    "        \n",
    "        # Fallback to local cache\n",
    "        return self.local_cache.get(key)\n",
    "    \n",
    "    async def set(self, key: str, value: Any, ttl: int = None) -> None:\n",
    "        \"\"\"Set value in cache\"\"\"\n",
    "        ttl = ttl or self.default_ttl\n",
    "        \n",
    "        if self.redis_client:\n",
    "            try:\n",
    "                self.redis_client.setex(key, ttl, pickle.dumps(value))\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Redis set failed: {e}\")\n",
    "        \n",
    "        # Fallback to local cache\n",
    "        self.local_cache[key] = value\n",
    "\n",
    "class RAGMetrics:\n",
    "    \"\"\"Prometheus metrics for RAG system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.query_counter = Counter('rag_queries_total', 'Total number of queries')\n",
    "        self.query_duration = Histogram('rag_query_duration_seconds', 'Query processing duration')\n",
    "        self.query_errors = Counter('rag_query_errors_total', 'Total number of query errors')\n",
    "        self.active_connections = Gauge('rag_active_connections', 'Number of active connections')\n",
    "        \n",
    "    def start_server(self, port: int = 8000):\n",
    "        \"\"\"Start metrics server\"\"\"\n",
    "        start_http_server(port)\n",
    "        logger.info(f\"Metrics server started on port {port}\")\n",
    "    \n",
    "    def record_query_success(self, duration: float):\n",
    "        \"\"\"Record successful query\"\"\"\n",
    "        self.query_counter.inc()\n",
    "        self.query_duration.observe(duration)\n",
    "    \n",
    "    def record_query_error(self, error: str):\n",
    "        \"\"\"Record query error\"\"\"\n",
    "        self.query_errors.inc()\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get metrics summary\"\"\"\n",
    "        return {\n",
    "            \"total_queries\": self.query_counter._value.get(),\n",
    "            \"total_errors\": self.query_errors._value.get(),\n",
    "            \"error_rate\": self.query_errors._value.get() / max(self.query_counter._value.get(), 1)\n",
    "        }\n",
    "\n",
    "# Test production RAG system\n",
    "print(\"üß™ Testing Production RAG System:\")\n",
    "\n",
    "# Create production system\n",
    "production_rag = ProductionRAGSystem(enable_monitoring=True)\n",
    "\n",
    "# Test query processing\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does artificial intelligence work?\",\n",
    "    \"Explain deep learning algorithms\"\n",
    "]\n",
    "\n",
    "print(f\"üîç Testing production patterns with {len(test_queries)} queries:\")\n",
    "\n",
    "for i, query in enumerate(test_queries):\n",
    "    print(f\"\\nQuery {i+1}: '{query}'\")\n",
    "    \n",
    "    result = await production_rag.process_query(query, user_id=f\"user_{i}\")\n",
    "    \n",
    "    print(f\"  Response: {result['response'][:100]}...\")\n",
    "    print(f\"  Request ID: {result['request_id']}\")\n",
    "    print(f\"  Fallback: {result.get('fallback', False)}\")\n",
    "    print(f\"  Timestamp: {result['timestamp']}\")\n",
    "\n",
    "# Get system health\n",
    "print(f\"\\nüè• System Health:\")\n",
    "health = production_rag.get_system_health()\n",
    "print(f\"  Status: {health['status']}\")\n",
    "print(f\"  Components:\")\n",
    "for component, status in health['components'].items():\n",
    "    print(f\"    {component}: {status}\")\n",
    "\n",
    "if 'metrics' in health:\n",
    "    print(f\"  Metrics:\")\n",
    "    for metric, value in health['metrics'].items():\n",
    "        print(f\"    {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c07e76",
   "metadata": {},
   "source": [
    "## Key Takeaways & Next Steps\n",
    "\n",
    "### What We've Built\n",
    "‚úÖ **Production RAG System** with enterprise patterns\n",
    "‚úÖ **Circuit Breaker** for fault tolerance\n",
    "‚úÖ **Caching System** with Redis and local fallback\n",
    "‚úÖ **Monitoring & Metrics** with Prometheus\n",
    "‚úÖ **Health Checks** for system monitoring\n",
    "‚úÖ **Error Handling** with fallback responses\n",
    "‚úÖ **Logging** for debugging and auditing\n",
    "\n",
    "### Key Production Patterns\n",
    "1. **Circuit Breaker**: Prevents cascade failures\n",
    "2. **Caching**: Improves performance and reduces costs\n",
    "3. **Monitoring**: Essential for production systems\n",
    "4. **Health Checks**: Ensure system reliability\n",
    "5. **Error Handling**: Graceful degradation\n",
    "6. **Logging**: Debugging and auditing\n",
    "\n",
    "### Next Steps\n",
    "- **Deployment**: Deploy to production environment\n",
    "- **Scaling**: Implement horizontal scaling\n",
    "- **Security**: Add authentication and authorization\n",
    "- **Compliance**: Meet regulatory requirements\n",
    "- **Monitoring**: Set up alerting and dashboards\n",
    "\n",
    "### Advanced Topics to Explore\n",
    "- **Kubernetes**: Container orchestration\n",
    "- **Service Mesh**: Advanced networking\n",
    "- **Event Sourcing**: Event-driven architecture\n",
    "- **CQRS**: Command Query Responsibility Segregation\n",
    "- **Saga Pattern**: Distributed transactions\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to deploy RAG to production?** Start with a simple deployment, then gradually add more sophisticated patterns based on your specific requirements!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
