{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478cbd5c",
   "metadata": {},
   "source": [
    "# Prompt Engineering: Complete Guide to Better LLM Responses\n",
    "\n",
    "## Learning Objectives\n",
    "- Master essential prompt engineering techniques\n",
    "- Understand when and how to apply each technique\n",
    "- Practice with real-world examples and code\n",
    "- Learn to optimize prompts for different use cases\n",
    "- Build confidence in crafting effective prompts\n",
    "\n",
    "## What You'll Learn\n",
    "- **Basic Techniques**: Zero-shot, Few-shot, Role prompting\n",
    "- **Advanced Techniques**: Chain-of-Thought, ReAct, Meta-prompting\n",
    "- **Creative Techniques**: Style, Emotion, Contextual prompting\n",
    "- **Structured Techniques**: Goal decomposition, Self-critique\n",
    "- **Practical Applications**: Real-world examples with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../utils')\n",
    "\n",
    "from llm_providers import LLMHelper, get_available_providers\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM helper\n",
    "llm_helper = LLMHelper()\n",
    "\n",
    "print(\"üöÄ Prompt Engineering Lab Setup Complete!\")\n",
    "print(f\"Available providers: {get_available_providers()}\")\n",
    "\n",
    "# Test basic functionality\n",
    "if llm_helper.is_available():\n",
    "    print(\"‚úÖ LLM provider ready for prompt engineering experiments\")\n",
    "else:\n",
    "    print(\"‚ùå No LLM provider available. Please check your API keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520e5ce",
   "metadata": {},
   "source": [
    "## 1. Zero-Shot Prompting\n",
    "\n",
    "**Core Idea**: Ask the model to perform a task directly without examples.\n",
    "\n",
    "**When to Use**:\n",
    "- Simple questions and answers\n",
    "- Basic text summarization\n",
    "- Quick brainstorming\n",
    "- When the LLM has enough general understanding\n",
    "\n",
    "**Key**: Add context like target audience for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7424db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Prompting Examples\n",
    "\n",
    "def test_zero_shot():\n",
    "    \"\"\"Demonstrate zero-shot prompting with and without context\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Contextual\n",
    "    basic_prompt = \"What is photosynthesis?\"\n",
    "    contextual_prompt = \"Explain photosynthesis to a 5-year-old child.\"\n",
    "    \n",
    "    print(\"üî¨ Basic Zero-Shot:\")\n",
    "    print(f\"Prompt: {basic_prompt}\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=150)\n",
    "    print(f\"Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"üë∂ Contextual Zero-Shot:\")\n",
    "    print(f\"Prompt: {contextual_prompt}\")\n",
    "    contextual_response = llm_helper.generate(contextual_prompt, max_tokens=150)\n",
    "    print(f\"Response: {llm_helper.format_response(contextual_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Different audiences\n",
    "    audiences = [\n",
    "        \"a high school student\",\n",
    "        \"a professional scientist\", \n",
    "        \"a business executive\"\n",
    "    ]\n",
    "    \n",
    "    topic = \"artificial intelligence\"\n",
    "    \n",
    "    print(\"üéØ Zero-Shot with Different Audiences:\")\n",
    "    for audience in audiences:\n",
    "        prompt = f\"Explain {topic} to {audience}.\"\n",
    "        response = llm_helper.generate(prompt, max_tokens=100)\n",
    "        print(f\"Audience: {audience}\")\n",
    "        print(f\"Response: {llm_helper.format_response(response)}\\n\")\n",
    "\n",
    "# Run the test\n",
    "test_zero_shot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c17953",
   "metadata": {},
   "source": [
    "## 2. Few-Shot Prompting\n",
    "\n",
    "**Core Idea**: Provide examples (input/output pairs) to show the model the desired task and format.\n",
    "\n",
    "**When to Use**:\n",
    "- Sentiment analysis with specific labels\n",
    "- Code generation in specific style\n",
    "- Data extraction or reformatting\n",
    "- Non-standard text generation\n",
    "\n",
    "**Key**: Include clear examples before your actual query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314abff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Prompting Examples\n",
    "\n",
    "def test_few_shot():\n",
    "    \"\"\"Demonstrate few-shot prompting with different tasks\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Sentiment Analysis\n",
    "    sentiment_examples = \"\"\"Classify: 'This is the best movie I have ever seen!'\n",
    "Positive\n",
    "\n",
    "Classify: 'I hated this film, it was a waste of time.'\n",
    "Negative\n",
    "\n",
    "Classify: 'The movie was okay, not great but not terrible.'\n",
    "Neutral\n",
    "\n",
    "Classify: 'The movie was okay, not great but not terrible.'\"\"\"\n",
    "    \n",
    "    print(\"üòä Few-Shot Sentiment Analysis:\")\n",
    "    print(\"Task: Movie review sentiment classification\")\n",
    "    sentiment_response = llm_helper.generate(sentiment_examples, max_tokens=50)\n",
    "    print(f\"Response: {llm_helper.format_response(sentiment_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Code Generation\n",
    "    code_examples = \"\"\"User: Write a Python function to calculate factorial\n",
    "Assistant: \n",
    "```python\n",
    "def factorial(n):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    return n * factorial(n - 1)\n",
    "```\n",
    "\n",
    "User: Write a Python function to check if a number is prime\n",
    "Assistant:\"\"\"\n",
    "    \n",
    "    print(\"üêç Few-Shot Code Generation:\")\n",
    "    print(\"Task: Python function generation\")\n",
    "    code_response = llm_helper.generate(code_examples, max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(code_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Data Formatting\n",
    "    format_examples = \"\"\"User: Convert this to JSON: Name: John, Age: 30, City: New York\n",
    "Assistant: {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n",
    "\n",
    "User: Convert this to JSON: Product: Laptop, Price: $999, In Stock: Yes\n",
    "Assistant:\"\"\"\n",
    "    \n",
    "    print(\"üìä Few-Shot Data Formatting:\")\n",
    "    print(\"Task: JSON conversion\")\n",
    "    format_response = llm_helper.generate(format_examples, max_tokens=100)\n",
    "    print(f\"Response: {llm_helper.format_response(format_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_few_shot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05167175",
   "metadata": {},
   "source": [
    "## 3. Role Prompting\n",
    "\n",
    "**Core Idea**: Instruct the LLM to adopt a specific persona or character.\n",
    "\n",
    "**When to Use**:\n",
    "- Making interactions more engaging\n",
    "- Explanations for specific audiences\n",
    "- Creative content in particular voice\n",
    "- Simulating expert perspectives\n",
    "\n",
    "**Key**: Use \"You are [Role]...\" in system prompt or start of user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role Prompting Examples\n",
    "\n",
    "def test_role_prompting():\n",
    "    \"\"\"Demonstrate role prompting with different personas\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Role-based\n",
    "    basic_prompt = \"Tell me about black holes.\"\n",
    "    role_prompt = \"\"\"You are Professor Astra, a friendly and slightly eccentric astronomer who loves making complex concepts accessible through analogies and enthusiasm. \n",
    "\n",
    "Professor Astra, I'm curious! Can you tell me all about those mysterious black holes?\"\"\"\n",
    "    \n",
    "    print(\"üåü Basic vs Role Prompting:\")\n",
    "    print(\"Basic prompt: Tell me about black holes\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=200)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Role-based prompt: Professor Astra explaining black holes\")\n",
    "    role_response = llm_helper.generate(role_prompt, max_tokens=200)\n",
    "    print(f\"Role Response: {llm_helper.format_response(role_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Chef Role\n",
    "    chef_prompt = \"\"\"You are Chef Marco, an Italian master chef with 30 years of experience. You're passionate about authentic Italian cuisine and love sharing cooking tips.\n",
    "\n",
    "Chef Marco, I want to make the perfect pasta carbonara. Can you guide me through it?\"\"\"\n",
    "    \n",
    "    print(\"üë®‚Äçüç≥ Chef Role:\")\n",
    "    print(\"Prompt: Chef Marco teaching pasta carbonara\")\n",
    "    chef_response = llm_helper.generate(chef_prompt, max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(chef_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Technical Writer Role\n",
    "    writer_prompt = \"\"\"You are a senior technical writer at a software company. You excel at creating clear, concise documentation that developers love to read.\n",
    "\n",
    "I need you to explain how to implement a REST API endpoint for user authentication. Make it clear and practical.\"\"\"\n",
    "    \n",
    "    print(\"üìù Technical Writer Role:\")\n",
    "    print(\"Prompt: Technical writer explaining REST API\")\n",
    "    writer_response = llm_helper.generate(writer_prompt, max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(writer_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_role_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544658a7",
   "metadata": {},
   "source": [
    "## 4. Style Prompting\n",
    "\n",
    "**Core Idea**: Guide the LLM to write in a particular literary, artistic, or formal style.\n",
    "\n",
    "**When to Use**:\n",
    "- Creative writing (stories, poems)\n",
    "- Content adaptation for different audiences\n",
    "- Matching specific brand voice\n",
    "- Academic or professional writing\n",
    "\n",
    "**Key**: Specify the desired style explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style Prompting Examples\n",
    "\n",
    "def test_style_prompting():\n",
    "    \"\"\"Demonstrate style prompting with different writing styles\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    base_content = \"Write a short description of a sunset over the ocean.\"\n",
    "    \n",
    "    # Example 1: Basic vs Haiku\n",
    "    basic_prompt = \"Write a short description of a sunset.\"\n",
    "    haiku_prompt = \"Write a short description of a sunset in the style of a haiku.\"\n",
    "    \n",
    "    print(\"üé® Basic vs Style Prompting:\")\n",
    "    print(\"Basic prompt: Write a short description of a sunset\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=150)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Haiku style: Write a short description of a sunset in the style of a haiku\")\n",
    "    haiku_response = llm_helper.generate(haiku_prompt, max_tokens=150)\n",
    "    print(f\"Haiku Response: {llm_helper.format_response(haiku_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Different styles\n",
    "    styles = [\n",
    "        (\"Hemingway\", \"Write a short description of a sunset over the ocean in the style of Ernest Hemingway.\"),\n",
    "        (\"Shakespeare\", \"Write a short description of a sunset over the ocean in the style of Shakespeare.\"),\n",
    "        (\"Technical\", \"Write a short description of a sunset over the ocean in a technical, scientific style.\"),\n",
    "        (\"Poetic\", \"Write a short description of a sunset over the ocean in a highly poetic, romantic style.\")\n",
    "    ]\n",
    "    \n",
    "    print(\"üé® Style Prompting Examples:\")\n",
    "    print(f\"Base content: {base_content}\\n\")\n",
    "    \n",
    "    for style_name, prompt in styles:\n",
    "        print(f\"üìù {style_name} Style:\")\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        response = llm_helper.generate(prompt, max_tokens=150)\n",
    "        print(f\"Response: {llm_helper.format_response(response)}\\n\")\n",
    "\n",
    "# Run the test\n",
    "test_style_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e4d8c",
   "metadata": {},
   "source": [
    "## 5. Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "**Core Idea**: Encourage the LLM to \"think step by step\" for multi-step reasoning tasks.\n",
    "\n",
    "**When to Use**:\n",
    "- Mathematical word problems\n",
    "- Logical reasoning puzzles\n",
    "- Commonsense reasoning\n",
    "- Complex problem solving\n",
    "\n",
    "**Key**: Add \"Let's think step by step\" or provide examples showing reasoning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d820151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-Thought Prompting Examples\n",
    "\n",
    "def test_chain_of_thought():\n",
    "    \"\"\"Demonstrate chain-of-thought prompting for complex reasoning\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Math Word Problem\n",
    "    math_problem_before = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\"\n",
    "    math_problem_after = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? Let's think step by step.\"\n",
    "    \n",
    "    print(\"üßÆ Chain-of-Thought Math Problem:\")\n",
    "    print(\"Before (direct): Roger has 5 tennis balls...\")\n",
    "    before_response = llm_helper.generate(math_problem_before, max_tokens=100)\n",
    "    print(f\"Direct Response: {llm_helper.format_response(before_response)}\\n\")\n",
    "    \n",
    "    print(\"After (with CoT): Roger has 5 tennis balls... Let's think step by step.\")\n",
    "    after_response = llm_helper.generate(math_problem_after, max_tokens=200)\n",
    "    print(f\"CoT Response: {llm_helper.format_response(after_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Logic Puzzle\n",
    "    logic_puzzle = \"A farmer has 17 sheep. All but 9 die. How many sheep are left? Let's think step by step.\"\n",
    "    \n",
    "    print(\"üß© Chain-of-Thought Logic Puzzle:\")\n",
    "    print(f\"Puzzle: {logic_puzzle}\")\n",
    "    logic_response = llm_helper.generate(logic_puzzle, max_tokens=150)\n",
    "    print(f\"Response: {llm_helper.format_response(logic_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Few-Shot CoT\n",
    "    few_shot_cot = \"\"\"Solve this step by step:\n",
    "\n",
    "Example 1:\n",
    "Problem: Sarah has 12 apples. She gives 3 to her friend and buys 7 more. How many apples does she have?\n",
    "Solution: \n",
    "- Sarah starts with 12 apples\n",
    "- She gives away 3: 12 - 3 = 9 apples\n",
    "- She buys 7 more: 9 + 7 = 16 apples\n",
    "- Answer: 16 apples\n",
    "\n",
    "Example 2:\n",
    "Problem: A store has 50 items. They sell 15 items in the morning and 20 items in the afternoon. How many items are left?\n",
    "Solution:\n",
    "- Store starts with 50 items\n",
    "- Morning sales: 50 - 15 = 35 items\n",
    "- Afternoon sales: 35 - 20 = 15 items\n",
    "- Answer: 15 items\n",
    "\n",
    "Now solve this:\n",
    "Problem: Tom has $100. He spends $25 on groceries and $30 on gas. His friend pays him back $15. How much money does Tom have now?\n",
    "Solution:\"\"\"\n",
    "    \n",
    "    print(\"üìö Few-Shot Chain-of-Thought:\")\n",
    "    print(\"Problem: Tom's money calculation\")\n",
    "    few_shot_response = llm_helper.generate(few_shot_cot, max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(few_shot_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_chain_of_thought()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15967773",
   "metadata": {},
   "source": [
    "## 6. ReAct (Reason + Act) Prompting\n",
    "\n",
    "**Core Idea**: Enable LLMs to solve complex tasks by interleaving reasoning with simulated actions.\n",
    "\n",
    "**When to Use**:\n",
    "- Multi-hop question answering\n",
    "- Fact verification\n",
    "- Complex problem solving\n",
    "- Making problem-solving process explicit\n",
    "\n",
    "**Key**: Follow \"Thought, Action, Observation\" cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211acb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct Prompting Examples\n",
    "\n",
    "def test_react_prompting():\n",
    "    \"\"\"Demonstrate ReAct prompting for complex reasoning\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Multi-hop Question\n",
    "    react_question = \"\"\"Answer the following question: \"Who was the U.S. president when the first person walked on the moon, and what was the name of that astronaut?\"\n",
    "\n",
    "To answer this, please follow a ReAct-like process. For each step, state:\n",
    "Thought: [Your reasoning or plan for the next step]\n",
    "Action: [The specific information you need to find or the sub-question you need to answer, as if you were querying a tool or database]\n",
    "Observation: [The hypothetical result or answer to your Action]\n",
    "\n",
    "Continue this process until you have all the information to answer the main question. Then, provide the final answer.\"\"\"\n",
    "    \n",
    "    print(\"ü§î ReAct Multi-hop Question:\")\n",
    "    print(\"Question: Who was the U.S. president when the first person walked on the moon?\")\n",
    "    react_response = llm_helper.generate(react_question, max_tokens=300)\n",
    "    print(f\"Response: {llm_helper.format_response(react_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Problem Solving\n",
    "    problem_solving = \"\"\"Solve this problem using ReAct methodology:\n",
    "\n",
    "Problem: \"A company has 3 departments. Department A has 25 employees, Department B has 30% more employees than Department A, and Department C has 20% fewer employees than Department B. How many total employees are there?\"\n",
    "\n",
    "Follow this format:\n",
    "Thought: [analyze what you need to calculate]\n",
    "Action: [identify the calculation steps]\n",
    "Observation: [work through each step]\n",
    "Final Answer: [your conclusion]\"\"\"\n",
    "    \n",
    "    print(\"üè¢ ReAct Problem Solving:\")\n",
    "    print(\"Problem: Company employee calculation\")\n",
    "    problem_response = llm_helper.generate(problem_solving, max_tokens=300)\n",
    "    print(f\"Response: {llm_helper.format_response(problem_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_react_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b2c04",
   "metadata": {},
   "source": [
    "## 7. Self-Critique & Refinement\n",
    "\n",
    "**Core Idea**: Instruct the LLM to generate, critique, and refine its own response.\n",
    "\n",
    "**When to Use**:\n",
    "- Improving creative tasks\n",
    "- Ensuring clarity and accuracy\n",
    "- Refining summaries\n",
    "- Reviewing generated code\n",
    "\n",
    "**Key**: Provide explicit steps for generation, critique, and refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263480c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Critique & Refinement Examples\n",
    "\n",
    "def test_self_critique():\n",
    "    \"\"\"Demonstrate self-critique and refinement prompting\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Self-Critique\n",
    "    basic_prompt = \"Write a short, catchy slogan for a new eco-friendly water bottle.\"\n",
    "    critique_prompt = \"\"\"I need a short, catchy slogan for a new eco-friendly water bottle. Please follow these steps:\n",
    "\n",
    "1. First, generate one initial slogan.\n",
    "2. Then, critically evaluate your own slogan:\n",
    "   - Is it catchy and memorable?\n",
    "   - Does it clearly communicate \"eco-friendly\"?\n",
    "   - Does it relate well to a \"water bottle\"?\n",
    "   - What are its weaknesses or areas for improvement?\n",
    "3. Finally, based on your critique, provide an improved slogan.\"\"\"\n",
    "    \n",
    "    print(\"üéØ Basic vs Self-Critique:\")\n",
    "    print(\"Basic prompt: Write a short, catchy slogan\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=100)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Self-Critique prompt: Generate, critique, and improve\")\n",
    "    critique_response = llm_helper.generate(critique_prompt, max_tokens=300)\n",
    "    print(f\"Self-Critique Response: {llm_helper.format_response(critique_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Code Review\n",
    "    code_review_task = \"\"\"I need you to write and review a Python function. Please follow these steps:\n",
    "\n",
    "1. Write a function that finds the longest word in a string\n",
    "2. Critically review your code:\n",
    "   - Is it efficient?\n",
    "   - Does it handle edge cases?\n",
    "   - Is it readable and well-documented?\n",
    "   - What could be improved?\n",
    "3. Provide an improved version based on your critique\n",
    "\n",
    "Format as:\n",
    "Initial Code: [your first attempt]\n",
    "Code Review: [your analysis]\n",
    "Improved Code: [your refined version]\"\"\"\n",
    "    \n",
    "    print(\"üíª Self-Critique Code Review:\")\n",
    "    print(\"Task: Longest word function\")\n",
    "    code_response = llm_helper.generate(code_review_task, max_tokens=400)\n",
    "    print(f\"Response: {llm_helper.format_response(code_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_self_critique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a937759",
   "metadata": {},
   "source": [
    "## 8. Meta-Prompting\n",
    "\n",
    "**Core Idea**: Use the LLM to help create better prompts for another task.\n",
    "\n",
    "**When to Use**:\n",
    "- Unsure how to phrase complex requests\n",
    "- Discovering more effective prompting methods\n",
    "- Optimizing prompts for quality or creativity\n",
    "\n",
    "**Key**: Describe the task and desired output characteristics, then ask for the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-Prompting Examples\n",
    "\n",
    "def test_meta_prompting():\n",
    "    \"\"\"Demonstrate meta-prompting for creating better prompts\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Fantasy Story Ideas\n",
    "    meta_prompt_1 = \"\"\"I want to use an LLM to generate 3 distinct and creative fantasy story ideas.\n",
    "\n",
    "For each story idea, I need the LLM to provide:\n",
    "a) A unique main character concept.\n",
    "b) A compelling central conflict.\n",
    "c) A unique magical element or system integral to the story.\n",
    "\n",
    "Please write out the actual, detailed prompt I should use to give to an LLM to get these structured fantasy story ideas.\"\"\"\n",
    "    \n",
    "    print(\"üßô Meta-Prompting: Fantasy Stories\")\n",
    "    print(\"Task: Create a prompt for fantasy story generation\")\n",
    "    meta_response_1 = llm_helper.generate(meta_prompt_1, max_tokens=300)\n",
    "    print(f\"Generated Prompt: {llm_helper.format_response(meta_response_1)}\\n\")\n",
    "    \n",
    "    # Example 2: Technical Documentation\n",
    "    meta_prompt_2 = \"\"\"I need to create a prompt that will help an LLM write excellent technical documentation for API endpoints. The documentation should be:\n",
    "- Clear and concise\n",
    "- Include code examples\n",
    "- Cover error handling\n",
    "- Be suitable for developers of all skill levels\n",
    "- Follow industry best practices\n",
    "\n",
    "Please write the exact prompt I should use to get high-quality API documentation from an LLM.\"\"\"\n",
    "    \n",
    "    print(\"üìö Meta-Prompting: API Documentation\")\n",
    "    print(\"Task: Create a prompt for API documentation\")\n",
    "    meta_response_2 = llm_helper.generate(meta_prompt_2, max_tokens=300)\n",
    "    print(f\"Generated Prompt: {llm_helper.format_response(meta_response_2)}\\n\")\n",
    "    \n",
    "    # Example 3: Marketing Copy\n",
    "    meta_prompt_3 = \"\"\"I want to create a prompt that generates compelling marketing copy for a new AI-powered productivity app. The copy should:\n",
    "- Appeal to busy professionals\n",
    "- Highlight key benefits clearly\n",
    "- Use persuasive language\n",
    "- Be concise but impactful\n",
    "- Include a strong call-to-action\n",
    "\n",
    "Write the exact prompt I should use to get effective marketing copy from an LLM.\"\"\"\n",
    "    \n",
    "    print(\"üì¢ Meta-Prompting: Marketing Copy\")\n",
    "    print(\"Task: Create a prompt for marketing copy\")\n",
    "    meta_response_3 = llm_helper.generate(meta_prompt_3, max_tokens=300)\n",
    "    print(f\"Generated Prompt: {llm_helper.format_response(meta_response_3)}\")\n",
    "\n",
    "# Run the test\n",
    "test_meta_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6362a",
   "metadata": {},
   "source": [
    "## 9. Emotion Prompting\n",
    "\n",
    "**Core Idea**: Instruct the LLM to generate a response conveying a specific emotion or from an emotional perspective.\n",
    "\n",
    "**When to Use**:\n",
    "- Adding emotional depth to creative writing\n",
    "- Crafting messages with specific sentiment\n",
    "- Generating empathetic customer service responses\n",
    "\n",
    "**Key**: Explicitly state the desired emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Prompting Examples\n",
    "\n",
    "def test_emotion_prompting():\n",
    "    \"\"\"Demonstrate emotion prompting with different emotional tones\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Emotional\n",
    "    basic_prompt = \"Write a thank you note for a gift I received.\"\n",
    "    emotional_prompt = \"Write a thank you note for a gift I received. Make it sound very excited and deeply grateful. The gift was a book I've wanted for ages and I was thrilled to get it!\"\n",
    "    \n",
    "    print(\"üòä Basic vs Emotion Prompting:\")\n",
    "    print(\"Basic prompt: Write a thank you note\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=150)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Emotional prompt: Excited and grateful thank you note\")\n",
    "    emotional_response = llm_helper.generate(emotional_prompt, max_tokens=150)\n",
    "    print(f\"Emotional Response: {llm_helper.format_response(emotional_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Apology Letter\n",
    "    apology_prompt = \"Write an apology letter to a friend. Make it sound sincere, remorseful, and hopeful for reconciliation. The situation is that you missed their important birthday celebration.\"\n",
    "    \n",
    "    print(\"üòî Emotion Prompting - Apology Letter:\")\n",
    "    print(\"Task: Sincere and remorseful apology\")\n",
    "    apology_response = llm_helper.generate(apology_prompt, max_tokens=150)\n",
    "    print(f\"Response: {llm_helper.format_response(apology_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Motivational Message\n",
    "    motivation_prompt = \"Write a motivational message for someone starting a new job. Make it sound enthusiastic, encouraging, and confident about their success.\"\n",
    "    \n",
    "    print(\"üí™ Emotion Prompting - Motivational Message:\")\n",
    "    print(\"Task: Enthusiastic and encouraging message\")\n",
    "    motivation_response = llm_helper.generate(motivation_prompt, max_tokens=150)\n",
    "    print(f\"Response: {llm_helper.format_response(motivation_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_emotion_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0cc4b",
   "metadata": {},
   "source": [
    "## 10. Contextual Prompting\n",
    "\n",
    "**Core Idea**: Provide the LLM with sufficient background information relevant to the request.\n",
    "\n",
    "**When to Use**:\n",
    "- Personalized recommendations\n",
    "- Problem-solving with specific data\n",
    "- Content generation about specific topics\n",
    "- Multi-turn conversations\n",
    "\n",
    "**Key**: Include all necessary details, history, preferences, or constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextual Prompting Examples\n",
    "\n",
    "def test_contextual_prompting():\n",
    "    \"\"\"Demonstrate contextual prompting with background information\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Contextual\n",
    "    basic_prompt = \"Suggest a gift.\"\n",
    "    contextual_prompt = \"\"\"I need a gift suggestion. Here's some context:\n",
    "- Recipient: My sister, she's 30 years old.\n",
    "- Occasion: Her birthday.\n",
    "- Interests: She loves reading fantasy novels, gardening, and trying new loose-leaf teas.\n",
    "- Budget: Around $50.\n",
    "Suggest a thoughtful gift based on this.\"\"\"\n",
    "    \n",
    "    print(\"üéÅ Basic vs Contextual Prompting:\")\n",
    "    print(\"Basic prompt: Suggest a gift\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=150)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Contextual prompt: Detailed gift suggestion with context\")\n",
    "    contextual_response = llm_helper.generate(contextual_prompt, max_tokens=200)\n",
    "    print(f\"Contextual Response: {llm_helper.format_response(contextual_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Business Problem\n",
    "    business_prompt = \"\"\"Context: You are helping a small business owner who runs a local coffee shop. They have limited technical knowledge but need to understand their options for improving customer experience.\n",
    "\n",
    "Question: What technology solutions would you recommend for a small coffee shop to improve customer experience and operations?\"\"\"\n",
    "    \n",
    "    print(\"üè™ Contextual Prompting - Business Advice:\")\n",
    "    print(\"Task: Technology recommendations for coffee shop\")\n",
    "    business_response = llm_helper.generate(business_prompt, max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(business_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Travel Planning\n",
    "    travel_prompt = \"\"\"I'm planning a trip to Japan. I'm a first-time visitor, interested in both traditional culture and modern technology. I have 7 days, prefer budget accommodations, and I'm traveling solo. I don't speak Japanese but I'm willing to learn basic phrases.\"\"\"\n",
    "    \n",
    "    print(\"‚úàÔ∏è Contextual Prompting - Travel Planning:\")\n",
    "    print(\"Task: Japan travel itinerary for first-time visitor\")\n",
    "    travel_response = llm_helper.generate(travel_prompt, max_tokens=250)\n",
    "    print(f\"Response: {llm_helper.format_response(travel_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_contextual_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c61f64",
   "metadata": {},
   "source": [
    "## 11. System Prompting\n",
    "\n",
    "**Core Idea**: Provide high-level instructions, context, or persona guidelines in the \"system message\" to apply across an entire conversation.\n",
    "\n",
    "**When to Use**:\n",
    "- Ensuring consistent LLM behavior or persona\n",
    "- Defining overall goals or constraints for a session\n",
    "- Simplifying user prompts by offloading standing instructions\n",
    "\n",
    "**Key**: Use the `system` role for persistent instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompting Examples\n",
    "\n",
    "def test_system_prompting():\n",
    "    \"\"\"Demonstrate system prompting for consistent behavior\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs System Prompt\n",
    "    text_to_summarize = \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower. Locally nicknamed 'La dame de fer' (French for 'Iron Lady'), it was constructed from 1887 to 1889 as the centerpiece of the 1889 World's Fair. Although initially criticized by some of France's leading artists and intellectuals for its design, it has become a global cultural icon of France and one of the most recognizable structures in the world.\"\n",
    "    \n",
    "    basic_prompt = f\"Summarize the following text in one sentence: '{text_to_summarize}'\"\n",
    "    system_prompt = \"You are a 'Concise Summarizer'. Your primary goal is to provide the shortest possible, grammatically correct summary that captures the main essence of any text provided. For all summaries, aim for just one clear sentence unless explicitly instructed otherwise.\"\n",
    "    \n",
    "    print(\"üìù Basic vs System Prompting:\")\n",
    "    print(\"Basic prompt: Summarize in one sentence\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=100)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"System prompt: Concise summarizer with persistent instructions\")\n",
    "    system_response = llm_helper.generate(f\"{system_prompt}\\n\\nUser: {text_to_summarize}\", max_tokens=100)\n",
    "    print(f\"System Response: {llm_helper.format_response(system_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Code Reviewer\n",
    "    code_reviewer_system = \"You are a senior code reviewer. Always provide constructive feedback focusing on: 1) Code efficiency, 2) Readability and maintainability, 3) Security considerations, 4) Best practices. Be specific and suggest improvements.\"\n",
    "    \n",
    "    user_code = \"\"\"def calculate_average(numbers):\n",
    "    total = 0\n",
    "    for i in range(len(numbers)):\n",
    "        total += numbers[i]\n",
    "    return total / len(numbers)\"\"\"\n",
    "    \n",
    "    print(\"üíª System Prompting - Code Reviewer:\")\n",
    "    print(\"System: Code review instructions\")\n",
    "    print(f\"User: {user_code}\")\n",
    "    code_review_response = llm_helper.generate(f\"{code_reviewer_system}\\n\\nUser: {user_code}\", max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(code_review_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Creative Writing Assistant\n",
    "    creative_system = \"You are a creative writing assistant. Always help writers develop their ideas with vivid descriptions, engaging dialogue, and compelling character development. Focus on showing rather than telling.\"\n",
    "    \n",
    "    user_request = \"I want to write a story about a detective who can see ghosts. Help me develop the opening scene.\"\n",
    "    \n",
    "    print(\"‚úçÔ∏è System Prompting - Creative Writing Assistant:\")\n",
    "    print(\"System: Creative writing guidance\")\n",
    "    print(f\"User: {user_request}\")\n",
    "    creative_response = llm_helper.generate(f\"{creative_system}\\n\\nUser: {user_request}\", max_tokens=250)\n",
    "    print(f\"Response: {llm_helper.format_response(creative_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_system_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01460a",
   "metadata": {},
   "source": [
    "## 12. Explicit Instructions Prompting\n",
    "\n",
    "**Core Idea**: Be crystal clear, direct, and unambiguous in your requests, leaving little room for misinterpretation.\n",
    "\n",
    "**When to Use**:\n",
    "- Specific output structure or content requirements\n",
    "- Avoiding certain topics\n",
    "- When length or conciseness is important\n",
    "- Complex tasks that could be interpreted in multiple ways\n",
    "\n",
    "**Key**: Detail exactly what you want: format, length, content to include/exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d609986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit Instructions Prompting Examples\n",
    "\n",
    "def test_explicit_instructions():\n",
    "    \"\"\"Demonstrate explicit instructions for precise outputs\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Explicit\n",
    "    basic_prompt = \"Write about apples.\"\n",
    "    explicit_prompt = \"\"\"Write a short paragraph about apples focusing on their nutritional benefits and common varieties.\n",
    "The paragraph should be exactly 3 sentences long.\n",
    "Mention at least two specific varieties (e.g., Granny Smith, Fuji).\n",
    "Do not discuss apple cultivation or history.\"\"\"\n",
    "    \n",
    "    print(\"üçé Basic vs Explicit Instructions:\")\n",
    "    print(\"Basic prompt: Write about apples\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=150)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Explicit prompt: Specific content with exact requirements\")\n",
    "    explicit_response = llm_helper.generate(explicit_prompt, max_tokens=150)\n",
    "    print(f\"Explicit Response: {llm_helper.format_response(explicit_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Format Specification\n",
    "    format_prompt = \"\"\"Create a product comparison table for three smartphones. Format as a markdown table with columns: Model, Price, Camera, Battery Life, Storage. Include exactly 3 models. Keep descriptions brief (1-2 words per cell).\"\"\"\n",
    "    \n",
    "    print(\"üì± Explicit Instructions - Product Comparison:\")\n",
    "    print(\"Task: Structured table with specific format\")\n",
    "    format_response = llm_helper.generate(format_prompt, max_tokens=200)\n",
    "    print(f\"Response: {llm_helper.format_response(format_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Content Restrictions\n",
    "    email_prompt = \"\"\"Write a professional email to a client about a project delay. Requirements: 1) Keep it under 100 words, 2) Use a professional but apologetic tone, 3) Include a specific new deadline, 4) Do not mention internal team issues or technical problems, 5) End with a call to action.\"\"\"\n",
    "    \n",
    "    print(\"üìß Explicit Instructions - Professional Email:\")\n",
    "    print(\"Task: Email with specific constraints and requirements\")\n",
    "    email_response = llm_helper.generate(email_prompt, max_tokens=150)\n",
    "    print(f\"Response: {llm_helper.format_response(email_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_explicit_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e523053",
   "metadata": {},
   "source": [
    "## 13. Output Priming\n",
    "\n",
    "**Core Idea**: Provide the LLM with the beginning of its desired response, nudging it towards a specific structure, format, or tone.\n",
    "\n",
    "**When to Use**:\n",
    "- Guiding output format (e.g., lists, JSON)\n",
    "- Ensuring a specific tone or starting phrase\n",
    "- Structured responses\n",
    "\n",
    "**Key**: End the user's message to naturally lead into the desired output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ba021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Priming Examples\n",
    "\n",
    "def test_output_priming():\n",
    "    \"\"\"Demonstrate output priming for structured responses\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Primed\n",
    "    basic_prompt = \"What are the ingredients for a simple vanilla cake?\"\n",
    "    primed_prompt = \"\"\"What are the ingredients for a simple vanilla cake? Please list them out.\n",
    "\n",
    "Here are the ingredients for a simple vanilla cake:\n",
    "-\"\"\"\n",
    "    \n",
    "    print(\"üì± Basic vs Output Priming:\")\n",
    "    print(\"Basic prompt: What are the ingredients for a simple vanilla cake?\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=200)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Primed prompt: Ingredients with list priming\")\n",
    "    primed_response = llm_helper.generate(primed_prompt, max_tokens=200)\n",
    "    print(f\"Primed Response: Here are the ingredients for a simple vanilla cake:\\n- {llm_helper.format_response(primed_response)}\\n\")\n",
    "    \n",
    "    # Example 2: JSON Format\n",
    "    json_prompt = \"\"\"Convert this information to JSON format: Name: Alice Johnson, Age: 28, Occupation: Software Engineer, City: San Francisco.\n",
    "\n",
    "{\n",
    "  \"name\":\"\"\"\n",
    "    \n",
    "    print(\"üìä Output Priming - JSON Format:\")\n",
    "    print(\"Task: JSON conversion with priming\")\n",
    "    json_response = llm_helper.generate(json_prompt, max_tokens=100)\n",
    "    print(f\"Response: {llm_helper.format_response(json_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Story Beginning\n",
    "    story_prompt = \"\"\"Write a short story about a time traveler who accidentally changes history. Make it engaging and include dialogue.\n",
    "\n",
    "The alarm blared as Dr. Sarah Chen realized her mistake. \"This can't be happening,\" she whispered, staring at the newspaper headline that shouldn't exist.\"\"\"\n",
    "    \n",
    "    print(\"üìö Output Priming - Story Beginning:\")\n",
    "    print(\"Task: Story with specific opening\")\n",
    "    story_response = llm_helper.generate(story_prompt, max_tokens=250)\n",
    "    print(f\"Response: {llm_helper.format_response(story_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_output_priming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d43e36",
   "metadata": {},
   "source": [
    "## 14. Rephrase and Respond (RaR)\n",
    "\n",
    "**Core Idea**: Ask the LLM to first rephrase your request or explain its understanding of the task before generating the main response.\n",
    "\n",
    "**When to Use**:\n",
    "- Complex, multi-faceted, or potentially ambiguous requests\n",
    "- When the cost of an incorrect response is high\n",
    "- To ensure the LLM has grasped all key constraints\n",
    "\n",
    "**Key**: \"First, briefly describe what kind of [task] you are planning to write about... Then, write [the task].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rephrase and Respond (RaR) Examples\n",
    "\n",
    "def test_rephrase_and_respond():\n",
    "    \"\"\"Demonstrate RaR prompting for complex tasks\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs RaR\n",
    "    basic_prompt = \"Write a story about a journey.\"\n",
    "    rar_prompt = \"\"\"I'd like a story about a journey.\n",
    "First, briefly describe what kind of journey you are planning to write about (e.g., is it an adventure, an emotional journey, a short trip, a long quest? Who is the main character?).\n",
    "Then, write a short story (around 100 words) based on your description.\"\"\"\n",
    "    \n",
    "    print(\"üìñ Basic vs RaR:\")\n",
    "    print(\"Basic prompt: Write a story about a journey\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=200)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"RaR prompt: Story with planning phase\")\n",
    "    rar_response = llm_helper.generate(rar_prompt, max_tokens=300)\n",
    "    print(f\"RaR Response: {llm_helper.format_response(rar_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Technical Documentation\n",
    "    tech_rar_prompt = \"\"\"I need you to create technical documentation for a new API endpoint. First, explain what type of documentation you plan to create, what sections you'll include, and who the target audience is. Then, write the actual documentation.\"\"\"\n",
    "    \n",
    "    print(\"üìö RaR - Technical Documentation:\")\n",
    "    print(\"Task: API documentation with planning\")\n",
    "    tech_response = llm_helper.generate(tech_rar_prompt, max_tokens=350)\n",
    "    print(f\"Response: {llm_helper.format_response(tech_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Business Strategy\n",
    "    business_rar_prompt = \"\"\"I want you to develop a marketing strategy for a new product launch. First, outline what type of strategy you're planning to create, what key elements you'll focus on, and what assumptions you're making. Then, provide the detailed strategy.\"\"\"\n",
    "    \n",
    "    print(\"üíº RaR - Business Strategy:\")\n",
    "    print(\"Task: Marketing strategy with planning\")\n",
    "    business_response = llm_helper.generate(business_rar_prompt, max_tokens=400)\n",
    "    print(f\"Response: {llm_helper.format_response(business_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_rephrase_and_respond()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae90583",
   "metadata": {},
   "source": [
    "## 15. Step-Back Prompting\n",
    "\n",
    "**Core Idea**: Guide the LLM to first consider broader concepts, principles, or general knowledge related to a specific question before answering it.\n",
    "\n",
    "**When to Use**:\n",
    "- Questions involving nuanced distinctions or definitions\n",
    "- Complex or debated topics\n",
    "- Problem-solving that benefits from first-principles thinking\n",
    "\n",
    "**Key**: Ask the LLM to explain general principles first, then apply them to the specific query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-Back Prompting Examples\n",
    "\n",
    "def test_step_back_prompting():\n",
    "    \"\"\"Demonstrate step-back prompting for complex questions\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Basic vs Step-Back\n",
    "    basic_prompt = \"Is a tomato a fruit or a vegetable?\"\n",
    "    step_back_prompt = \"\"\"I have a question about tomatoes. But first, please explain:\n",
    "1. What is the botanical definition of a fruit?\n",
    "2. What is the general culinary understanding of a vegetable?\n",
    "\n",
    "Now, using those definitions, explain whether a tomato is considered a fruit or a vegetable, and clarify why there's often confusion.\"\"\"\n",
    "    \n",
    "    print(\"üçÖ Basic vs Step-Back Prompting:\")\n",
    "    print(\"Basic prompt: Is a tomato a fruit or a vegetable?\")\n",
    "    basic_response = llm_helper.generate(basic_prompt, max_tokens=200)\n",
    "    print(f\"Basic Response: {llm_helper.format_response(basic_response)}\\n\")\n",
    "    \n",
    "    print(\"Step-Back prompt: Botanical vs culinary definitions\")\n",
    "    step_back_response = llm_helper.generate(step_back_prompt, max_tokens=300)\n",
    "    print(f\"Step-Back Response: {llm_helper.format_response(step_back_response)}\\n\")\n",
    "    \n",
    "    # Example 2: AI Ethics\n",
    "    ai_ethics_prompt = \"\"\"Before answering my specific question, please first explain: 1. What are the fundamental principles of AI ethics? 2. What is the difference between bias and fairness in AI systems? 3. What are the key considerations for responsible AI development? Now, apply these concepts to this question: Should AI systems be allowed to make decisions about hiring without human oversight?\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ Step-Back - AI Ethics:\")\n",
    "    print(\"Task: AI ethics principles before specific question\")\n",
    "    ai_response = llm_helper.generate(ai_ethics_prompt, max_tokens=400)\n",
    "    print(f\"Response: {llm_helper.format_response(ai_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Economic Concepts\n",
    "    economics_prompt = \"\"\"I want to understand inflation better. First, please explain: 1. What is the basic definition of inflation? 2. What are the main causes of inflation? 3. What are the different types of inflation? Now, using these concepts, explain why some economists argue that moderate inflation can be beneficial for an economy.\"\"\"\n",
    "    \n",
    "    print(\"üí∞ Step-Back - Economic Concepts:\")\n",
    "    print(\"Task: Inflation fundamentals before analysis\")\n",
    "    economics_response = llm_helper.generate(economics_prompt, max_tokens=350)\n",
    "    print(f\"Response: {llm_helper.format_response(economics_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_step_back_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4033c53",
   "metadata": {},
   "source": [
    "## 16. Thread-of-Thought (ThoT)\n",
    "\n",
    "**Core Idea**: Encourage the LLM to maintain a coherent and connected line of reasoning or narrative across multiple turns or a long piece of generated text.\n",
    "\n",
    "**When to Use**:\n",
    "- Long-form content generation (essays, articles)\n",
    "- Complex explanations requiring logical flow\n",
    "- Multi-turn problem solving\n",
    "- Extended conversations to maintain focus\n",
    "\n",
    "**Key**: Provide a structured outline and explicitly ask for logical flow and transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread-of-Thought (ThoT) Examples\n",
    "\n",
    "def test_thread_of_thought():\n",
    "    \"\"\"Demonstrate thread-of-thought for coherent long-form content\"\"\"\n",
    "    \n",
    "    if not llm_helper.is_available():\n",
    "        print(\"‚ùå No LLM available for testing\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Process Explanation\n",
    "    thot_prompt = \"\"\"I need a clear explanation of how a bill becomes a law in the US.\n",
    "Please structure your explanation as follows:\n",
    "\n",
    "1. **Introduction:** Briefly state the overall purpose of the legislative process.\n",
    "2. **Bill Introduction:** Explain who can introduce a bill and where.\n",
    "3. **Committee Stage:** Describe what happens in committees and why this stage is important. Ensure you explain how this connects to the previous step.\n",
    "4. **Floor Action (House/Senate):** Detail the debate and voting process in one chamber. Explain how a bill gets from committee to the floor.\n",
    "5. **Action in the Other Chamber:** Explain that the process is repeated and what happens if versions differ. Clearly link this to the previous chamber's action.\n",
    "6. **Conference Committee (if needed):** Explain its role in reconciling differences.\n",
    "7. **Presidential Action:** Describe the President's options (sign, veto, pocket veto) and the consequences.\n",
    "8. **Overriding a Veto (if applicable):** Explain this final potential step.\n",
    "\n",
    "Throughout your explanation, ensure each stage logically follows the previous one, maintaining a clear \"thread\" of the bill's journey. Use clear transition phrases.\"\"\"\n",
    "    \n",
    "    print(\"üìú Thread-of-Thought - Legislative Process:\")\n",
    "    print(\"Task: Coherent explanation of bill-to-law process\")\n",
    "    thot_response = llm_helper.generate(thot_prompt, max_tokens=400)\n",
    "    print(f\"Response: {llm_helper.format_response(thot_response)}\\n\")\n",
    "    \n",
    "    # Example 2: Scientific Explanation\n",
    "    science_thot_prompt = \"\"\"Explain the process of photosynthesis in detail. Structure your explanation as: 1. Overview of the process, 2. Light-dependent reactions, 3. Light-independent reactions (Calvin cycle), 4. Factors affecting photosynthesis, 5. Importance to ecosystems. Ensure each section builds upon the previous one and use transition phrases to maintain the logical flow.\"\"\"\n",
    "    \n",
    "    print(\"üå± Thread-of-Thought - Photosynthesis:\")\n",
    "    print(\"Task: Coherent scientific explanation\")\n",
    "    science_response = llm_helper.generate(science_thot_prompt, max_tokens=450)\n",
    "    print(f\"Response: {llm_helper.format_response(science_response)}\\n\")\n",
    "    \n",
    "    # Example 3: Problem-Solving Process\n",
    "    debug_thot_prompt = \"\"\"Describe a systematic approach to debugging software issues. Structure your explanation as: 1. Initial problem assessment, 2. Information gathering, 3. Hypothesis formation, 4. Testing and validation, 5. Solution implementation, 6. Prevention strategies. Maintain a logical progression from problem identification to solution, with each step building on the previous one.\"\"\"\n",
    "    \n",
    "    print(\"üêõ Thread-of-Thought - Debugging Process:\")\n",
    "    print(\"Task: Systematic problem-solving approach\")\n",
    "    debug_response = llm_helper.generate(debug_thot_prompt, max_tokens=400)\n",
    "    print(f\"Response: {llm_helper.format_response(debug_response)}\")\n",
    "\n",
    "# Run the test\n",
    "test_thread_of_thought()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2d4b6",
   "metadata": {},
   "source": [
    "## 17. Summary and Next Steps\n",
    "\n",
    "### üéâ **What You've Learned**\n",
    "\n",
    "You've mastered essential prompt engineering techniques:\n",
    "\n",
    "**Basic Techniques**:\n",
    "- Zero-shot prompting\n",
    "- Few-shot prompting  \n",
    "- Role prompting\n",
    "- Style prompting\n",
    "\n",
    "**Advanced Techniques**:\n",
    "- Chain-of-Thought (CoT)\n",
    "- ReAct (Reason + Act)\n",
    "- Self-Critique & Refinement\n",
    "- Meta-prompting\n",
    "\n",
    "**Creative Techniques**:\n",
    "- Emotion prompting\n",
    "- Contextual prompting\n",
    "- Output priming\n",
    "- Goal decomposition\n",
    "\n",
    "**Structured Techniques**:\n",
    "- System prompting\n",
    "- Explicit instructions\n",
    "- Rephrase and Respond (RaR)\n",
    "- Step-back prompting\n",
    "- Thread-of-Thought (ThoT)\n",
    "\n",
    "### üöÄ **Next Steps**\n",
    "\n",
    "1. **Practice**: Try these techniques with your own use cases\n",
    "2. **Experiment**: Combine multiple techniques for complex tasks\n",
    "3. **Iterate**: Refine your prompts based on results\n",
    "4. **Document**: Keep track of what works best for different scenarios\n",
    "\n",
    "### üìö **Further Learning**\n",
    "\n",
    "- **RAG Systems**: Next notebook covers retrieval-augmented generation\n",
    "- **Conversational AI**: Learn about multi-turn conversations\n",
    "- **Production Optimization**: Scale your prompt engineering skills\n",
    "\n",
    "### üí° **Pro Tips**\n",
    "\n",
    "- Start simple, then add complexity\n",
    "- Test with different models to see variations\n",
    "- Keep a library of effective prompt templates\n",
    "- Measure success with specific metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
